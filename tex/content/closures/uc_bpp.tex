\documentclass[../../diss.tex]{subfiles}
\begin{document}

\section{Upward closures for BPP nets}%
\label{Section:UCBPP}%

The doubly exponential state complexity of upward closures in the case of Petri net coverability languages motivates studying a restricted version.
In \cref{Section:PNBPP}, we have already introduced BPP nets as a version of Petri nets in which transitions may consume at most one token.
This restricts the expressiveness of the model compared to general Petri nets, but still leads to an interesting theory, \eg the possibility to express non-context-free languages with such nets.
With respect to their practical applicability, note that BPP nets correspond to concurrent systems in which threads cannot communicate after they have been spawned, as modeled by the calculus of basic parallel processes~\cite{Christensen93}.
Regarding the algorithmics of BPP nets, it is well known that both the coverability and the reachability problem of BPP nets are $\NPTIME$-complete, compared to $\EXPSPACE$-complete and Ackermann-complete for general Petri nets.
Altogether, computing the language closures for BPP net languages is an interesting problem for which it is reasonable to hope for a better computational and state complexity than in the case of general Petri nets.
We formalize this problem in the case of computing the upward closure as follows.

\begin{compproblem}
    \problemtitle{Computing the upward closure for BPP net languages}
    \problemshort{($\BPPUC$)}
    \probleminput{A labeled BPP net instance $(N,\Minit,\Mfinal)$.}
    \problemquestion{An NFA $A$ with $\lang{A} = \uc{\lang{N,\Minit,\Mfinal}}$.}
\end{compproblem}

We show that this restriction improves the state complexity as well as the time needed to construct the NFA to be singly exponential.
The following theorem formalizes this.

\begin{theorem}%
\label{Theorem:BPPUCGeneral}%
    Upward closures of BPP net coverability languages have exponential state complexity, and the corresponding automata can be constructed in exponential time. These bounds are tight.
\end{theorem}

We proceed as we did when proving the result for general Petri nets:
Firstly, we show the upper bound, then the lower bound, and finally, we discuss the case of using a unary encoding.

\paragraph{Upper bound}

The goal of this part of the section is to prove the upper bound.

\begin{theorem}%
\label{Theorem:BPPUC}%
    Given a labeled BPP net instances $(N,\Minit,\Mfinal)$, we can compute in exponential time an NFA $A$ with $\lang{A} = \uc{\lang{N,\Minit,\Mfinal}}$.
    The state complexity of $\uc{\lang{N,\Minit,\Mfinal}}$ is at most exponential, as witnessed by automaton $A$.
\end{theorem}

We proceed similar as in \cref{Section:PNUC}:
We show that the minimal words in the upward closure are generated by computations of a bounded length.
However, to establish the bound, we cannot reuse the argumentation from before.
Simply using the fact that the given net is a BPP net does not lead to a modification of the proof of \cref{Proposition:PNRackoffRecursiveBound} that yields an improved bound.
Instead, we have to come up with a new proof approach.

We will establish that the bound is a number that depends on the transitions of the net and the amount of tokens assigned by the final marking.
Since we are considering a binary encoding, the latter may be exponential in the size of the instance.
Hence, $k$ is exponential in the size of the given net.
Once this result has been proven, we can proceed as in the proof of \cref{Theorem:PNUC}: We obtain the upward closure as the upward closure of the regular length-$k$ underapproximation of the BPP net.

The bound is formalized in the form of the following proposition.

\begin{proposition}%
\label{Proposition:BPPBound}%
    For every covering computation $\Minit \fire{\sigma} M \geq \Mfinal$ there is a firing sequence $\sigma'$ such that $\Minit \fire{\sigma\lowerprime} M \geq \Mfinal$, $\lambda(\sigma') \subword \lambda(\sigma)$ and $\card{\sigma'} \leq k = \paren{\normone{\Mfinal}}^2 \cdot \paren{\card{T} + 1}$.
\end{proposition}

Before giving the proof, we introduce the unfolding of a BPP net, a construction that we will need in the following.
The correctness of the construction will rely on an additional restriction:
We require that each transition in the given BPP net consumes exactly one token.
If the BPP net contains a \emph{spontaneous} transition that consumes no token, we apply the following preprocessing.
We introduce a new place $p$ and let the initial marking put one token on this place.
We also introduce a new $\eps$-labeled transition $t_{\text{gen}}$ with $\i(t,p) = 1$, $\o(t,p) = 2$ that allows us to generate an arbitrary number of tokens on this place.
Every spontaneous transition $t$ with $\i(t) = \vec{0}$ is modified so that it consumes one token from place $p$.
The final marking does not require any tokens on $p$.

The net that results from the processing is a BPP net in which every transition consumes exactly one token.
It is only polynomially larger than the original net.
Furthermore, it has the same language:
A computation of the original net can be turned into a computation of the new net that generates the same word by inserting a suitable number of firings of transition $t_{\text{gen}}$ at the beginning, and vice versa.

Hence, we may assume in the following that the preprocessing has already been applied to the net $N$; it contains no spontaneous transitions.
We consider its unfolding, the infinite BPP net obtained by unfolding the transitions so that each layer of transitions produces tokens on a fresh layer of places.
Any computation of $N$ corresponds to a computation in a finite prefix of the unfolding.
Combining the fact that the unfolding moves the tokens to fresh places after each transition and the defining properties of BPPs, this corresponding computation has a forest-like structure.
By backtracking the tokens from the marking that has to been covered, we identify subtrees in the unfolding that induce a computation in the BPP net consisting of at most $\paren{\normone{\Mfinal}}^2 \cdot \card{T}$ transitions.
Note that this bound is subtly different from the bound $\paren{\normone{\Mfinal}}^2 \cdot \paren{\card{T} +1}$ stated in \cref{Proposition:BPPBound}.
This is to take the new transition into account which is added by the preprocessing.

Unfoldings of Petri nets are a standard notion in research on Petri nets~\cite{EsparzaH08} and not a contribution of this thesis.
Unfoldings are a true concurrency semantics for Petri nets, meaning they are the true concurrency analogue of the computation tree, the latter being used for sequential models of computation.
On the one hand, the unfolding represents all possible computations, just as a computation tree does.
On the other hand, it reflects the concurrent nature of Petri nets by keeping track of the flow of each token individually.

To make this formal, we consider occurrence nets $O = (P', T', \i',\o')$, which are defined like (unlabeled) BPP nets with the following modifications:
(1) $O$ may be infinite.
(2) Each place has at most one incoming transition.
(3) Each transition creates at most one token per place.
\mbox{(4) $O$ seen} as directed graph is acyclic.

We call two elements $x,y \in P'\dotcup T'$ \emph{causally related} and write $x \causal y$ if there is a path from $x$ to $y$ in $O$ seen as graph.
Note that this is a partial order on the nodes of the graph: Reflexivity and transitivity obviously hold true, while antisymmetry is guaranteed by $O$ being acyclic.
%
We use $\causalpredec{x}=\Set{y\in P'\cup T'}{y \causal x}$ to denote the ancestors of $x\in P'\cup T'$.
As suggested by the notation, this is indeed the downward closure of the set $\set{x}$ \wrt the relation $\causal$.
The $\causal$-minimal places are denoted by $\min O$.
Because the relation $\causal$ is antisymmetric, this set is uniquely determined,
The initial marking of $O$ is fixed to put one token in each place of $\min O$ and no tokens elsewhere.

Occurrence nets (together with their initial marking) are $1$-safe, \ie each place can carry at most one token in any reachable marking.
This allows us to identify markings with subsets $P'' \subseteq P'$ by assuming that $P''$ contains exactly the places that carry a token.
Similarly, we may write $P_1'\fire{t\lowprime}P_2'$ for subsets $P_1', P_2'\subseteq P'$.

To associate an occurrence net $O$ to a BPP net $N$ together with an initial marking $\Minit$, we use the notion of \emph{folding homomorphisms}.
Such a homomorphism is a function $h:P' \cup T' \rightarrow P \cup T$.
For a place $p$ of the original net, we think of all places $p'$ of $O$ with $h(p') = p$ as \emph{copies} of $p$, similar for the transitions.

A folding homomorphism should satisfy three properties, but in order to state them, we will need some more notation.
We extend $h$ to a function that, given a subset $P'' \subseteq P'$ of places of $O$, returns the marking $h(P'') \in \N^P$ defined by $h(P'')(p) = \card{\Set{p'\in P_1'}{h(p')=p}}$, \ie we count all tokens assigned to copies of place $p$.
Furthermore, we may use that transitions in $O$ consume and produce at most token per place and see $\i'(t)$ and $\o'(t)$ as subsets of $P'$ (for some \nb{transition $t$}).
This allows us to consider $h(\i'(t))$ and $h(\o'(t))$ as markings.

%
\cheatpagebreak
%

The three properties of folding homomorphisms are the following:

\begin{enumerate}[(1)]
     \item
         Initiation:
         The initial marking of $O$ maps to the initial marking of $N$,
         $h(\min O)=\Minit$.
     \item\label{Property:FoldingHomomorphismConsecution}
         Consecution: $\i'$ and $\o'$ map to $\i$ and $\o$:
         For all $t'\in T'$:
         $h(\i'(t')) = \i(h(t'))$, $h(\o'(t')) = \o(h(t'))$.
     \item
         Irredundancy:
         For all $t_1',t_2' \in T'$ with $\i(t_1') = \i(t_2')$ and $h(t_1') = h(t_2')$, we have $t_1' = t_2'$.
\end{enumerate}

A pair $(O,h)$ consisting of an occurrence net $O$ and a folding homomorphism $h$ is called a \emph{branching process} of $(N, \Minit)$.
Branching processes are partially ordered by the prefix relation which, intuitively, states how far they unwind the BPP.\@
The limit of the unwinding process is the \emph{unfolding} $\text{Unf}(N, \Minit)$, the unique (up to isomorphism) maximum branching process.
Note that $\text{Unf}(N, \Minit)$ is infinite in general.

We forgo making this definition more formal.
Instead, we specify its properties on which we will rely in the following.
There is a correspondence between computations from $\Minit$ in $N$ and computations from the initial marking in $\text{Unf}(N, \Minit)$:
Each computation in $\text{Unf}(N, \Minit)$ induces a unique computation of $N$, and each computation of $N$ induces a set of computations that only differ by a permutation of the tokens.

Note that even if $\text{Unf}(N, \Minit)$ is infinite, each finite computation -- and in particular each computation induced by a finite computation of $N$ -- only uses places and transitions whose distance from $\min O$ is bounded by the length of the computation times two.

Recall that \cref{Proposition:BPPBound} requires us to prove that ever covering computation has a covering subcomputation consisting of at most $\paren{\normone{\Mfinal}}^2 \cdot \card{T}$ transitions.
(Note that this is the modified bound that takes the aforementioned preprocessing step into account.)
Using the unfolding, we can now prove this statement.

\begin{proof}[Proof of \cref{Proposition:BPPBound}]
    Consider the covering computation $\Minit \fire{\sigma} M \geq \Mfinal$ of the BPP net $N$.
    Let $(O, h)$ with $O=(P', T', \i',\o')$ be the unfolding $\text{Unf}(N, M_0)$.
    We pick $\min O \fire{\tau} P''$ as an arbitrary computation of $O$ corresponding to the computation of $N$, \ie $h(\tau) = \sigma$ and $h(P'') = M$.
    Using $M \geq \Mfinal$, for each place $p \in P$, the set $P''$ contains at least $\Mfinal(p)$ places $p'$ that get mapped to $p$ under $h$.
    For each place $p$, let $X_p \subseteq P''$ be a set of size $\Mfinal(p)$ of places $p'$ with $h(p') = p$.
    Let $X = \bigcup_{p \in P} X_p$ be their union, and note that $h(X) = \Mfinal$ holds by construction.

    Since we assume that every transition in the original net consumes exactly one token, so do the transitions in the unfolding.
    Furthermore, they produce at most one token per place, each place has at most one incoming transition and the unfolding is acyclic.
    Thus, each computation in the unfolding induces a forest in $O$ seen as graph.
    For each place in $\min O$, the forest contains a tree which is rooted in that place.
    The leaves of the forest correspond to places that carry a token in the marking reached by the computation.
    The inner nodes consist of places that carry a token at some point during the computation, and the transitions that are used in the computation.

    Let us consider this forest for the computation defined by the firing sequence $\tau$.
    Note that $X$ is a set of leaves by definition.
    We select the subforest induced by the set $\causalpredec{X}$, \ie the places in $X$, their ancestors in the graph and the edges connecting them.
    We project the firing sequence $\tau$ to the transitions occurring in this subforest, obtaining the sequence $\tau_1$.
    Since $\causalpredec{X}$ is downward closed \wrt the relation $\causal$, $\tau_1$ is a valid firing sequence from $\min O$ in the sense that all transitions are enabled whenever they are fired.
    Furthermore, $\tau_1$ still generates all tokens in $X$ and we have that $\min O \fire{\tau_1} P_1' \supseteq X$ is a covering computation in the sense that $h(P_1') \geq \Mfinal$.

    In the following, our goal is to delete transitions from $\tau_1$ so that the resulting sequence $\tau_2$ matches the bound $\card{\tau_2} \leq \paren{\normone{\Mfinal}}^2 \cdot \card{T}$.
    This will allow us to show that $h(\tau_2)$, its image under the folding homomorphism, is the sequence whose existence is required by the proposition.

    We first need to introduce a notion for the $\causal$-maximal transitions in $\tau$ that lead to at least two different places in $X$.
    Formally, a transition $t'$ is a \emph{join transition} if there are $x, y\in X$ with $t' \in \causalpredec{x} \cap \causalpredec{y}$ and there is no $t'' \in \causalpredec{x} \cap \causalpredec{y}$ with $t' \causal t''$.

    Assume that $t' \neq t''$ are two adjacent join transitions that occur on the same branch of the subforest with $t' \causal t''$.
    This means that $t' \itr{t}{1} \ldots \itr{t}{m} t''$ is an infix of the sequence of transitions along that branch, where none of the $\itr{t}{i}$ is a join transition.
    Note that for two places in $X$, there is either no join transition or a unique one leading to these two places, since join transitions are required to be $\causal$-maximal.
    Consequently, $t'$ and $t''$ have to lead to different places of $X$.

    Since $t', t''$ occur in $\tau_1$, all $\itr{t}{i}$ also have to occur in $\tau_1$.
    If there are indices $j < k$ such that $h(t^j) = h(t^k)$, we may delete $\itr{t}{j+1} \ldots \itr{t}{k}$ from $\tau_1$.
    To ensure validity of the computation, we need to modify $\itr{t}{k+1} \ldots \itr{t}{m}t''$:
    Transition $\itr{t}{k+1}$ should consume the token produced by $\itr{t}{j}$ (instead of the token produced by the deleted transition $\itr{t}{k}$) and so on.
    This is possible since $h(t_j) = h(t_k)$ implies $h(\i'(t_j)) = h(\i'(t_k))$ by Consecution, Property~\ref{Property:FoldingHomomorphismConsecution} of folding homomorphisms.
    Furthermore, we exhaustively need to delete from $\tau$ all transitions that rely on tokens that are not produced anymore, starting with transitions relying on tokens produced by the transitions $\itr{t}{j+1} \ldots \itr{t}{k}$.
    To see that the resulting computation still covers, note that we have not deleted any join transitions.
    Hence, the leaves of the subforest that are removed by deleting the transitions are not contained in $X$.

    We repeat this deletion process until we obtain that between each two join transitions of the same branch of the subforest, there are no repetitions, \ie transitions whose image under $h$ is the same.
    Let the resulting transition sequence be $\tau_2$, inducing the computation  $\min O \fire{\tau_2} P_2' \supseteq X$.
    Firstly, note that for any $x \in X$, there are at most $\normone{\Mfinal}$ join transitions on the branch from the corresponding minimal place to $x$:
    In the worst case, for each place in $X \setminus \set{x}$, there is a join transition on the branch, and $\card{X} = \normone{\Mfinal}$.
    Between any two adjacent join transitions along such a path, there are at most $\card{T}$ transitions in $\tau_2$
    Hence, the number of transitions in such a path is bounded by $\normone{\Mfinal} \cdot \card{T}$.
    Since we have $\normone{\Mfinal}$ places in $X$, the total number of transitions in $\tau_2$ is bounded by $\paren{\normone{\Mfinal}}^2 \cdot \card{T}$.

    To conclude the proof, consider the firing sequence $\sigma' = h(\tau_2)$ obtained by applying the folding homomorphism to $\tau_2$ and the computation $\Minit \fire{\sigma\lowerprime} M_2$ of $N$ that is induced by it.
    We indeed have $M_2 \geq \Mfinal$ since $M_2 = h(P_2) \geq h(X) = \Mfinal$ and $\card{\sigma'} = \card{h(\tau_2)} = \card{\tau_2} \leq \paren{\normone{\Mfinal}}^2 \cdot \card{T}$.
\end{proof}

With \cref{Proposition:BPPBound} at hand, we can prove \cref{Theorem:BPPUC}.
We consider the length-$k$ approximation for $k = \paren{\normone{\Mfinal}}^2 \cdot \card{T}$, and obtain an automaton for $\languak{k}{N,\Minit,\Mfinal}$ of size at most
\(
    \bigO{k^n \cdot 2^{n^2}}
\), see \cref{Proposition:PNLengthkApprox}.
We compute
\[
    k^n \cdot 2^{n^2}
    =
    \paren{\paren{\normone{\Mfinal}}^2 \cdot \paren{\card{T}+1}}^n \cdot 2^{n^2}
    \leq \paren{2^n \cdot \card{T}}^n \cdot 2^{n^2}
    = 2^{n^2} \cdot {\card{T}+1}^n \cdot 2^{n^2}
    = 2^{2 n^2} \cdot \paren{\card{T} +1}^n
    \ ,
\]
which is exponential as required.
The upward closure of the language of this automaton can be constructed without adding new states, see \cref{Section:PNRelwork}.
To show correctness, \ie this upward closure coinciding with the upward closure of the original BPP net language, we proceed exactly as in the proof of \cref{Theorem:PNUC}.

\paragraph{Lower Bound}

To prove that the above construction is optimal, we present a family of BPP languages for which the state complexity of the upward closure is exponential in the size of the nets.
The proof uses the fact that we can encode the exponential number $2^n$ occurring in the final marking using only $\log 2^n = n$ bits.

\begin{proposition}%
\label{Proposition:BPPUChardness}%
    For each $n \in \N$, there is a labeled BPP net instance $(N, \Minit, \Mfinal(n))$ of size polynomial in $n$ such that $\uc{\lang{N, \Minit, \Mfinal(n)}}$ has state complexity at least $2^n$.
\end{proposition}

\begin{proof}
    The net $N$ required to prove the proposition is depicted in \cref{Figure:BPPUCLowerBoundBinary}.
    It consists of a single place $p$, and a single $a$-labeled transition $t$ that produces a token on this place.
    The initial marking $\Minit$ is the zero vector, the final marking $\Mfinal$ requires $2^n$ tokens on $p$.

    Obviously, to cover the final marking, transition $t$ needs to be fired at least $2^n$ times.
    Hence, $\lang{N, \Minit, \Mfinal(n)} = \Set{ a^k }{ k \geq 2^n}$.
    This language is already upward closed and has state-complexity $2^n + 1$, see \cref{Example:StateComplexityEqualsIndex}.
    Both $N$ and $\Minit$ are of constant size.
    As mentioned above, $\size{\Mfinal}$ is of size polynomial in $n$ since the size of a marking is defined based on the length of the binary encoding of the numbers.
\end{proof}

\begin{figure}[t]%
    {\centering\subcaptionbox{In the binary case.\label{Figure:BPPUCLowerBoundBinary}}[0.3\textwidth][c]{
        \input{tikz/bpp_uc_lowerbound_binary.tikz}}
    }
    {\centering\subcaptionbox{In the unary case.\label{Figure:BPPUCLowerBoundUnary}}[0.65\textwidth][c]{
        \input{tikz/bpp_uc_lowerbound_unary.tikz}}
    }
    \caption{BPP nets to prove the exponential lower bound for the upward closure.}%
    \label{Figure:BPPUCLowerBound}%
\end{figure}

With the lower bound at hand, the proof of \cref{Theorem:BPPUCGeneral} is completed.

\paragraph{The unary case}

We complete our study by considering the case in which the BPP net is encoded in unary.
We start by inspecting the upper bound, noting that the bound $k = \paren{\normone{\Mfinal}}^2 \cdot \card{T}$ provided by \cref{Proposition:BPPBound} is polynomial in the size of the net if we consider the unary encoding.
However, we then use this bound to construct an automaton with state space $\oneto{k} \times (P \to \zeroto{(k+1) \cdot n})$.
This is a modification of \cref{Proposition:PNLengthkApprox} that takes into account that with the net of size $n$ being encoded in unary, each transition can add at most $n$ tokens.
This set of states is of size
\[
    (k+1) \cdot {(((k+1) \cdot n) + 1)}^{\card{P}}
    \ ,
\]
\ie it is exponential in the number of places, even if $k$ is a number that is polynomial in the size of the net.
In summary, we still obtain an exponential upper bound.

Let us see whether the lower bound matches.
Obviously, the net that we have constructed in \cref{Proposition:BPPUChardness} to prove the lower bound in the binary case does not do the job.
The net uses a final marking that requires $2^n$ tokens on a place, so its unary encoding is of exponential size.
Can a net with the language $\Set{a^k}{k \geq 2^n}$ whose unary encoding is polynomial in $n$ be constructed in a different way?
To the best of the author's knowledge, there is no such construction.
However, there is a different language that will provide a lower bound that matches the upper bound, \ie it is exponential in the number of places.

Let $n \in \N$, and consider an alphabet $\Sigma = \set{a_1, \ldots, a_n}$ of size $n$.
We define the language $\calL_{\text{all}}$ as the language of all words over $\Sigma$ that contain each letter at least once,
\[
    \calL_{\text{all}} = \Set{ w \in \Sigma^*}{ \forall i \in \oneto{n} \exists j \in \oneto{\card{w}} \colon w_j = a_i } = \Sigma^*a_1\Sigma^* \cap \ldots \cap \Sigma^* a_n \Sigma^*
    \ .
\]
This language and its complement $\overline{\calL_{\text{all}}}$, the set of words in which at least one letter does not occur, are well-known examples in the context of the state complexity of regular languages.
Both languages can be easily represented by a DFA of size $2^n$: The DFA has one state for each subset of $\Sigma$ and tracks the set of letters that have occurred.
One can find a small NFA of size $n+1$ that accepts $\overline{\calL_{\text{all}}}$ by initially guessing a letter that will not occur and verifying that guess later.
The same is not true for $\calL_{\text{all}}$: Any NFA for this language has at least $2^n$ states, just as the DFA.\@
Hence, the pair of languages shows that complementing a regular language can increase its state complexity exponentially.
This behavior has been first observed by \citea{SakodaS78}, although on a pair of languages that is more complex to define.
Later, \citea{Birget93} provided a simpler proof for this fact (but still based on the languages from~\cite{SakodaS78}).
This proof uses an extension of the fooling set technique for DFAs to NFAs.
For the sake of completeness, we give a proof for the fact that $\calL_{\text{all}}$ cannot be represented by a small NFA that uses the argumentation by Birget.

\begin{lemma}
    For each positive $n \in \N$, $\calL_{\text{all}}$ has state complexity $2^n$.
\end{lemma}

\begin{proof}
    As mentioned before, it is easy to construct a DFA -- which can be seen as NFA -- with the desired number of states.
    It remains to show that there is no NFA with a smaller number of states.

    Let us assume that $A$ is an NFA with $\lang{A} = \calL_{\text{all}}$.
    For each subset $\Gamma \subseteq \Sigma$ of the alphabet, we let $w_\Gamma$ be an arbitrary word that contains exactly the letters from $\Gamma$.
    For example, we may assume $\Gamma = \set{ a_{i_1}, \ldots, a_{i_{\card{\Gamma}}}}$ with $1 \leq i_1 < i_2 < \ldots < i_{\card{\Gamma}} \leq n$ and define $w_{\Gamma} = a_{i_1} \ldots a_{i_{\card{\Gamma}}}$.

    Note that for each $\Gamma \subseteq \Sigma$, the word $w_{\Gamma} . w_{\Sigma \setminus \Gamma}$ is an element of $\calL_{\text{all}}$ because it contains each letter.
    Hence, we can define the state $q_\Gamma$ to be the state that occurs after $w_{\Gamma}$ has been processed in an accepting run on $w_{\Gamma} . w_{\Sigma \setminus \Gamma}$, \ie
    \[
        q_\init \tow{ w_{\Gamma} } q_\Gamma \tow{ w_{\Sigma \setminus \Gamma} } q_\final \in Q_\final
        \ .
    \]
    If multiple accepting runs exist, we pick an arbitrary one.

    We claim that if $\Gamma \neq \Gamma'$ are two distinct subsets of $\Sigma$, then $q_\Gamma \neq q_\Gamma'$.
    Towards a contradiction, assume equality, \ie we have runs
    \[
        q_\init \tow{ w_{\Gamma} } q_\Gamma \tow{ w_{\Sigma \setminus \Gamma} } q_\final \in Q_\final
        \ ,
    \]
    \[
        q_\init \tow{ w_{\Gamma'} } q_\Gamma \tow{ w_{\Sigma \setminus \Gamma'} } q_\final' \in Q_\final
        \ .
    \]
    Since $\Gamma \neq \Gamma'$, there is some letter that occurs only in one of the subalphabets.
    \Wolog, we assume that $a_i \in \Gamma$, but $a_i \not \in \Gamma'$.
    Consider the word $w_{\Gamma'}.w_{\Sigma \setminus \Gamma}$.
    This word is not contained in $\calL_{\text{all}}$ because neither $w_{\Gamma'}$ nor $w_{\Sigma \setminus \Gamma}$ contain letter $a_i$.
    However, we can construct an accepting run $q_\init \tow{ w_{\Gamma'} } q_\Gamma \tow{ w_{\Sigma \setminus \Gamma} } q_\final \in Q_\final$ on that word, proving that it is contained in $\lang{A}$.
    We obtain a contradiction to $\lang{A} = \calL_{\text{all}}$.

    Hence, automaton $A$ needs to contain a distinct state $q_\Gamma$ for each subalphabet $\Gamma \subseteq \Sigma$.
    The number of subalphabets is $2^{\card{\Sigma}} = 2^n$, which means $A$ needs to have at least $2^n$ states.
    This completes the proof.
\end{proof}

With the lemma at hand, it remains to see that $\calL_{\text{all}}$ occurs as the language of a BPP net whose unary encoding is of size polynomial in $n$.
The required net is rather simple: It counts how often each letter has been generated.
We depict it in  \cref{Figure:BPPUCLowerBoundUnary}.
For each $i \in \oneto{n}$, there is a place $p_{a_i}$ and an $a_i$-labeled transition $t_{a_i}$ that consumes no tokens and produces a token on $p_{a_i}$.
The initial marking puts no tokens anywhere, while the final marking is $\vec{1}$, \ie it is covered once at least one token has been produced on every place.
Additionally, $\calL_{\text{all}}$ is an upward-closed language.

Altogether, we obtain matching lower and upper bounds: The state complexity of the upward closure of a BPP net is a number that is exponential in the number of places of the net.

\end{document}
